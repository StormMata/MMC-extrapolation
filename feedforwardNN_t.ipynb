{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3 Pro\n",
      "\n",
      "systemMemory: 36.00 GB\n",
      "maxCacheSize: 13.50 GB\n",
      "\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |num_layers\n",
      "192               |192               |units_0\n",
      "0.01              |0.01              |learning_rate\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 17:59:24.807523: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-11 17:59:24.807694: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-08-11 17:59:25.000941: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 816us/step - loss: 2911.1951 - mae: 22.4399 - val_loss: 12.0355 - val_mae: 2.7114\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 0s 563us/step - loss: 8.2371 - mae: 2.1764 - val_loss: 10.6041 - val_mae: 2.5404\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 0s 533us/step - loss: 7.4261 - mae: 2.0640 - val_loss: 10.5183 - val_mae: 2.5618\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 0s 547us/step - loss: 7.3667 - mae: 2.0581 - val_loss: 10.9354 - val_mae: 2.6266\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 0s 555us/step - loss: 7.3364 - mae: 2.0555 - val_loss: 10.9069 - val_mae: 2.6147\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 0s 550us/step - loss: 7.1608 - mae: 2.0216 - val_loss: 10.5763 - val_mae: 2.5760\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 0s 585us/step - loss: 7.1772 - mae: 2.0225 - val_loss: 10.1386 - val_mae: 2.4894\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 0s 530us/step - loss: 7.2414 - mae: 2.0343 - val_loss: 11.1530 - val_mae: 2.6329\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 0s 534us/step - loss: 7.1533 - mae: 2.0128 - val_loss: 10.5014 - val_mae: 2.5520\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 0s 577us/step - loss: 7.0486 - mae: 1.9908 - val_loss: 10.0309 - val_mae: 2.4798\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 0s 537us/step - loss: 7.1937 - mae: 2.0036 - val_loss: 9.8103 - val_mae: 2.4044\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 0s 506us/step - loss: 7.3172 - mae: 2.0216 - val_loss: 9.8456 - val_mae: 2.4554\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 0s 504us/step - loss: 6.8237 - mae: 1.9357 - val_loss: 9.8048 - val_mae: 2.4248\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 0s 536us/step - loss: 7.1562 - mae: 1.9896 - val_loss: 9.6717 - val_mae: 2.3993\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 0s 502us/step - loss: 7.2398 - mae: 1.9965 - val_loss: 11.0440 - val_mae: 2.6014\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 0s 502us/step - loss: 7.3099 - mae: 1.9896 - val_loss: 12.2478 - val_mae: 2.8448\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 0s 530us/step - loss: 7.3024 - mae: 2.0126 - val_loss: 9.3322 - val_mae: 2.3320\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 0s 504us/step - loss: 7.4738 - mae: 2.0445 - val_loss: 11.4391 - val_mae: 2.6403\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 0s 525us/step - loss: 7.1102 - mae: 1.9626 - val_loss: 19.1750 - val_mae: 3.5825\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 0s 523us/step - loss: 7.6761 - mae: 2.0686 - val_loss: 10.1442 - val_mae: 2.4349\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 0s 508us/step - loss: 8.0802 - mae: 2.1442 - val_loss: 11.4860 - val_mae: 2.6030\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 0s 513us/step - loss: 8.0061 - mae: 2.1180 - val_loss: 9.6252 - val_mae: 2.3893\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 0s 551us/step - loss: 8.4806 - mae: 2.2106 - val_loss: 8.9925 - val_mae: 2.2311\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 0s 528us/step - loss: 9.4784 - mae: 2.3237 - val_loss: 28.6209 - val_mae: 4.6007\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 0s 508us/step - loss: 8.8571 - mae: 2.2443 - val_loss: 20.1090 - val_mae: 3.7558\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 0s 492us/step - loss: 9.4659 - mae: 2.3656 - val_loss: 25.3997 - val_mae: 4.4029\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 0s 492us/step - loss: 9.8159 - mae: 2.4271 - val_loss: 14.2528 - val_mae: 3.0473\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 0s 605us/step - loss: 9.2873 - mae: 2.3475 - val_loss: 10.4434 - val_mae: 2.4513\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 0s 499us/step - loss: 9.1753 - mae: 2.3230 - val_loss: 10.4361 - val_mae: 2.3981\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 0s 489us/step - loss: 9.7834 - mae: 2.4007 - val_loss: 14.8169 - val_mae: 3.1678\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 0s 486us/step - loss: 8.9480 - mae: 2.2802 - val_loss: 8.9973 - val_mae: 2.2433\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 0s 488us/step - loss: 11.1072 - mae: 2.5997 - val_loss: 9.2076 - val_mae: 2.2604\n",
      "Epoch 33/50\n",
      "156/156 [==============================] - 0s 505us/step - loss: 8.5795 - mae: 2.2310 - val_loss: 13.5864 - val_mae: 2.8518\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 0s 519us/step - loss: 9.4315 - mae: 2.3517 - val_loss: 13.7213 - val_mae: 2.8165\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 0s 518us/step - loss: 9.6751 - mae: 2.3917 - val_loss: 14.4776 - val_mae: 3.0680\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 0s 521us/step - loss: 8.8167 - mae: 2.2628 - val_loss: 11.7060 - val_mae: 2.7422\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 0s 495us/step - loss: 11.5210 - mae: 2.6144 - val_loss: 9.8018 - val_mae: 2.3131\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 0s 622us/step - loss: 9.7383 - mae: 2.4112 - val_loss: 10.7902 - val_mae: 2.4880\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 0s 545us/step - loss: 10.2224 - mae: 2.4576 - val_loss: 9.2110 - val_mae: 2.2947\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 0s 513us/step - loss: 8.8264 - mae: 2.2668 - val_loss: 24.6216 - val_mae: 4.2862\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 0s 533us/step - loss: 11.5681 - mae: 2.6496 - val_loss: 10.4259 - val_mae: 2.4557\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 0s 518us/step - loss: 11.7462 - mae: 2.6813 - val_loss: 15.4481 - val_mae: 2.9676\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 0s 524us/step - loss: 8.9509 - mae: 2.2842 - val_loss: 17.1459 - val_mae: 3.1723\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 0s 515us/step - loss: 14.4771 - mae: 3.0421 - val_loss: 22.7182 - val_mae: 3.9792\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 0s 501us/step - loss: 9.6411 - mae: 2.4192 - val_loss: 22.7719 - val_mae: 3.8311\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 0s 504us/step - loss: 10.1092 - mae: 2.4478 - val_loss: 19.0997 - val_mae: 3.7278\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 0s 491us/step - loss: 10.8245 - mae: 2.5536 - val_loss: 9.7033 - val_mae: 2.3260\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 0s 497us/step - loss: 9.5999 - mae: 2.4015 - val_loss: 11.8875 - val_mae: 2.8206\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 0s 503us/step - loss: 8.5221 - mae: 2.2212 - val_loss: 10.4741 - val_mae: 2.5572\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 0s 492us/step - loss: 8.6563 - mae: 2.2440 - val_loss: 9.4455 - val_mae: 2.3602\n",
      "Epoch 1/50\n",
      "156/156 [==============================] - 0s 721us/step - loss: 3046.7002 - mae: 23.1496 - val_loss: 12.1465 - val_mae: 2.6655\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 0s 501us/step - loss: 8.0646 - mae: 2.1524 - val_loss: 11.2919 - val_mae: 2.6818\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 0s 490us/step - loss: 7.4568 - mae: 2.0724 - val_loss: 10.3271 - val_mae: 2.5329\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 0s 482us/step - loss: 7.2075 - mae: 2.0246 - val_loss: 10.2887 - val_mae: 2.5072\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 0s 485us/step - loss: 7.1765 - mae: 2.0205 - val_loss: 11.2038 - val_mae: 2.6504\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 0s 484us/step - loss: 7.2077 - mae: 2.0237 - val_loss: 10.3164 - val_mae: 2.5113\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 0s 497us/step - loss: 7.0145 - mae: 1.9877 - val_loss: 10.1484 - val_mae: 2.4967\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 0s 520us/step - loss: 6.8764 - mae: 1.9603 - val_loss: 10.1248 - val_mae: 2.5115\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 0s 544us/step - loss: 7.2848 - mae: 2.0232 - val_loss: 9.7728 - val_mae: 2.4374\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 0s 544us/step - loss: 6.7604 - mae: 1.9310 - val_loss: 10.6536 - val_mae: 2.5270\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 0s 559us/step - loss: 6.7694 - mae: 1.9178 - val_loss: 9.6916 - val_mae: 2.3830\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 0s 564us/step - loss: 6.6011 - mae: 1.8906 - val_loss: 9.3160 - val_mae: 2.3188\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 0s 540us/step - loss: 6.7856 - mae: 1.9142 - val_loss: 9.9303 - val_mae: 2.4484\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 0s 530us/step - loss: 7.4265 - mae: 2.0358 - val_loss: 9.8048 - val_mae: 2.3848\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 0s 511us/step - loss: 6.9920 - mae: 1.9531 - val_loss: 9.2356 - val_mae: 2.2851\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 0s 524us/step - loss: 6.8431 - mae: 1.9255 - val_loss: 9.3969 - val_mae: 2.3134\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 0s 542us/step - loss: 7.4782 - mae: 2.0416 - val_loss: 9.9538 - val_mae: 2.4347\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 0s 512us/step - loss: 7.0605 - mae: 1.9702 - val_loss: 9.7414 - val_mae: 2.3415\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 0s 519us/step - loss: 7.1334 - mae: 1.9800 - val_loss: 9.2699 - val_mae: 2.2755\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 0s 527us/step - loss: 7.1549 - mae: 1.9844 - val_loss: 9.2884 - val_mae: 2.3496\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 0s 534us/step - loss: 6.8159 - mae: 1.9155 - val_loss: 9.5798 - val_mae: 2.3233\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 0s 642us/step - loss: 7.5150 - mae: 2.0274 - val_loss: 36.6267 - val_mae: 5.3812\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 0s 513us/step - loss: 9.3768 - mae: 2.3330 - val_loss: 9.0993 - val_mae: 2.2417\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 0s 519us/step - loss: 7.4279 - mae: 2.0246 - val_loss: 10.4078 - val_mae: 2.5136\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 0s 512us/step - loss: 8.9516 - mae: 2.2558 - val_loss: 16.5856 - val_mae: 3.4062\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 0s 505us/step - loss: 9.1319 - mae: 2.3146 - val_loss: 11.3848 - val_mae: 2.6125\n",
      "Epoch 27/50\n",
      "  1/156 [..............................] - ETA: 0s - loss: 4.9721 - mae: 1.7516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y_train[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_train) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)], y_train[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_train) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m):]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m     79\u001b[0m best_hyperparameters \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1818\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1816\u001b[0m variables_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([])\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args):\n\u001b[0;32m-> 1818\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1819\u001b[0m     \u001b[38;5;66;03m# We can pass a variable more than once, and in this case we need to\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m     \u001b[38;5;66;03m# pass its handle only once.\u001b[39;00m\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(arg\u001b[38;5;241m.\u001b[39mhandle) \u001b[38;5;129;01min\u001b[39;00m variables_used:\n\u001b[1;32m   1822\u001b[0m       \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "\n",
    "    # Open velocity data set\n",
    "    ds = xr.open_dataset('/Users/smata/Downloads/processedData/temperatureData_30min.nc')\n",
    "\n",
    "    # Reformat to Pandas dataframe\n",
    "    df = ds['t'].to_dataframe().reset_index()\n",
    "\n",
    "    df = df.pivot(index = 'time', columns = 'height', values = 't')\n",
    "\n",
    "    df.columns = [f't_{int(height)}m' for height in df.columns]\n",
    "\n",
    "    df.insert(0, 'L',    ds.L.values)\n",
    "    df.insert(0, 'TKE',  ds.TKE.values)\n",
    "\n",
    "    df.insert(0, 'hour_sin', np.sin(2 * np.pi * ds.hr_day.values / 24))\n",
    "    df.insert(0, 'hour_cos', np.cos(2 * np.pi * ds.hr_day.values / 24))\n",
    "\n",
    "    df.insert(0, 'day_sin', np.sin(2 * np.pi * ds.day_yr.values / 365))\n",
    "    df.insert(0, 'day_cos', np.cos(2 * np.pi * ds.day_yr.values / 365))\n",
    "\n",
    "    # Standardize data\n",
    "    windCols      = [col for col in df.columns if col.startswith('t_')]\n",
    "    stabilityCols = ['TKE', 'L']\n",
    "\n",
    "    # Define and extract input and output columns\n",
    "    inputs = ['day_cos', 'day_sin', 'hour_cos', 'hour_sin', 'TKE', 'L', 't_10m']\n",
    "\n",
    "    X = df[inputs].values\n",
    "    y = df[windCols].values\n",
    "\n",
    "    # Create input and output arrays\n",
    "    split_index = int(0.8 * len(X))\n",
    "\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    # Define the model-building function\n",
    "    def build_model(hp):\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        # Choose number of layers\n",
    "        for i in range(hp.Int('num_layers', 1, 3)):\n",
    "            model.add(keras.layers.Dense(\n",
    "                units = hp.Int(f'units_{i}', min_value = 32, max_value = 512, step = 32),\n",
    "                activation = 'relu'))\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(keras.layers.Dense(y_train.shape[1]))  # Output size should match the number of wind components\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer = keras.optimizers.Adam(\n",
    "                hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
    "            ),\n",
    "            loss = 'mean_squared_error',\n",
    "            metrics = ['mae'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # Initialize the Keras Tuner\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective    = 'val_mae',\n",
    "        max_trials   = 10,\n",
    "        executions_per_trial = 3,\n",
    "        directory    = 'hyperparameter_tuning',\n",
    "        project_name = 'wind_forecast_nn'\n",
    "    )\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train, X_val = X_train[:int(len(X_train) * 0.8)], X_train[int(len(X_train) * 0.8):]\n",
    "    y_train, y_val = y_train[:int(len(y_train) * 0.8)], y_train[int(len(y_train) * 0.8):]\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    tuner.search(X_train, y_train, epochs = 50, validation_data = (X_val, y_val))\n",
    "\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Optimal number of layers:\", best_hyperparameters.get('num_layers'))\n",
    "    print(\"Optimal learning rate:\", best_hyperparameters.get('learning_rate'))\n",
    "    for i in range(best_hyperparameters.get('num_layers')):\n",
    "        print(f\"Optimal units in layer {i}: {best_hyperparameters.get(f'units_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
