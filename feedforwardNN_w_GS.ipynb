{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 675us/step - loss: 0.0246 - mae: 0.1047 - val_loss: 0.0083 - val_mae: 0.0707\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 390us/step - loss: 0.0075 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0636\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 393us/step - loss: 0.0067 - mae: 0.0624 - val_loss: 0.0070 - val_mae: 0.0632\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 410us/step - loss: 0.0068 - mae: 0.0622 - val_loss: 0.0064 - val_mae: 0.0630\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 410us/step - loss: 0.0067 - mae: 0.0620 - val_loss: 0.0062 - val_mae: 0.0607\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 402us/step - loss: 0.0069 - mae: 0.0631 - val_loss: 0.0077 - val_mae: 0.0692\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 389us/step - loss: 0.0069 - mae: 0.0629 - val_loss: 0.0067 - val_mae: 0.0630\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 396us/step - loss: 0.0070 - mae: 0.0638 - val_loss: 0.0076 - val_mae: 0.0678\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0074 - mae: 0.0653 - val_loss: 0.0069 - val_mae: 0.0639\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0075 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0630\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 387us/step - loss: 0.0073 - mae: 0.0650 - val_loss: 0.0074 - val_mae: 0.0670\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0075 - mae: 0.0658 - val_loss: 0.0075 - val_mae: 0.0669\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0075 - mae: 0.0656 - val_loss: 0.0093 - val_mae: 0.0749\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0078 - mae: 0.0674 - val_loss: 0.0065 - val_mae: 0.0615\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0075 - mae: 0.0661 - val_loss: 0.0075 - val_mae: 0.0673\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 387us/step - loss: 0.0080 - mae: 0.0680 - val_loss: 0.0090 - val_mae: 0.0757\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 399us/step - loss: 0.0081 - mae: 0.0683 - val_loss: 0.0079 - val_mae: 0.0693\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 403us/step - loss: 0.0082 - mae: 0.0685 - val_loss: 0.0064 - val_mae: 0.0611\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 397us/step - loss: 0.0080 - mae: 0.0680 - val_loss: 0.0067 - val_mae: 0.0618\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 383us/step - loss: 0.0081 - mae: 0.0682 - val_loss: 0.0070 - val_mae: 0.0638\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0082 - mae: 0.0685 - val_loss: 0.0083 - val_mae: 0.0722\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0082 - mae: 0.0687 - val_loss: 0.0086 - val_mae: 0.0715\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0082 - mae: 0.0687 - val_loss: 0.0075 - val_mae: 0.0675\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0086 - mae: 0.0703 - val_loss: 0.0067 - val_mae: 0.0645\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0086 - mae: 0.0706 - val_loss: 0.0088 - val_mae: 0.0728\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0079 - mae: 0.0672 - val_loss: 0.0072 - val_mae: 0.0641\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0076 - mae: 0.0660 - val_loss: 0.0081 - val_mae: 0.0696\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0075 - val_mae: 0.0651\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0082 - mae: 0.0689 - val_loss: 0.0067 - val_mae: 0.0632\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0082 - mae: 0.0693 - val_loss: 0.0082 - val_mae: 0.0691\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 366us/step - loss: 0.0077 - mae: 0.0664 - val_loss: 0.0067 - val_mae: 0.0635\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0087 - mae: 0.0705 - val_loss: 0.0072 - val_mae: 0.0658\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0082 - mae: 0.0691 - val_loss: 0.0068 - val_mae: 0.0623\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0082 - mae: 0.0689 - val_loss: 0.0072 - val_mae: 0.0651\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0078 - mae: 0.0668 - val_loss: 0.0064 - val_mae: 0.0611\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0076 - mae: 0.0656 - val_loss: 0.0064 - val_mae: 0.0610\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0090 - mae: 0.0723 - val_loss: 0.0092 - val_mae: 0.0729\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0083 - mae: 0.0691 - val_loss: 0.0069 - val_mae: 0.0638\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 526us/step - loss: 0.0078 - mae: 0.0670 - val_loss: 0.0108 - val_mae: 0.0822\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0079 - mae: 0.0672 - val_loss: 0.0066 - val_mae: 0.0619\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0077 - mae: 0.0665 - val_loss: 0.0064 - val_mae: 0.0614\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0078 - mae: 0.0667 - val_loss: 0.0078 - val_mae: 0.0690\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0076 - mae: 0.0660 - val_loss: 0.0075 - val_mae: 0.0671\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0080 - mae: 0.0673 - val_loss: 0.0069 - val_mae: 0.0644\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0076 - mae: 0.0656 - val_loss: 0.0069 - val_mae: 0.0633\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0077 - mae: 0.0664 - val_loss: 0.0063 - val_mae: 0.0607\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0079 - mae: 0.0670 - val_loss: 0.0068 - val_mae: 0.0632\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 412us/step - loss: 0.0080 - mae: 0.0672 - val_loss: 0.0065 - val_mae: 0.0624\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0083 - mae: 0.0683 - val_loss: 0.0102 - val_mae: 0.0794\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0081 - mae: 0.0682 - val_loss: 0.0083 - val_mae: 0.0693\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0077 - mae: 0.0657 - val_loss: 0.0083 - val_mae: 0.0708\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0078 - mae: 0.0669 - val_loss: 0.0069 - val_mae: 0.0635\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0079 - mae: 0.0670 - val_loss: 0.0078 - val_mae: 0.0673\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0074 - mae: 0.0646 - val_loss: 0.0082 - val_mae: 0.0694\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0081 - mae: 0.0676 - val_loss: 0.0079 - val_mae: 0.0691\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0076 - val_mae: 0.0680\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 429us/step - loss: 0.0083 - mae: 0.0686 - val_loss: 0.0080 - val_mae: 0.0676\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 389us/step - loss: 0.0079 - mae: 0.0670 - val_loss: 0.0072 - val_mae: 0.0654\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0066 - val_mae: 0.0618\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0079 - mae: 0.0670 - val_loss: 0.0075 - val_mae: 0.0658\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0083 - mae: 0.0687 - val_loss: 0.0087 - val_mae: 0.0709\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0083 - mae: 0.0686 - val_loss: 0.0077 - val_mae: 0.0677\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0079 - mae: 0.0671 - val_loss: 0.0077 - val_mae: 0.0682\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 383us/step - loss: 0.0078 - mae: 0.0666 - val_loss: 0.0080 - val_mae: 0.0683\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0080 - mae: 0.0676 - val_loss: 0.0071 - val_mae: 0.0635\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0080 - mae: 0.0676 - val_loss: 0.0077 - val_mae: 0.0666\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0080 - mae: 0.0676 - val_loss: 0.0103 - val_mae: 0.0775\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0076 - mae: 0.0657 - val_loss: 0.0072 - val_mae: 0.0645\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0077 - mae: 0.0662 - val_loss: 0.0077 - val_mae: 0.0669\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 381us/step - loss: 0.0082 - mae: 0.0683 - val_loss: 0.0071 - val_mae: 0.0653\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0080 - mae: 0.0673 - val_loss: 0.0073 - val_mae: 0.0643\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0076 - mae: 0.0656 - val_loss: 0.0068 - val_mae: 0.0623\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0078 - mae: 0.0667 - val_loss: 0.0081 - val_mae: 0.0692\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0082 - mae: 0.0682 - val_loss: 0.0093 - val_mae: 0.0740\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0077 - mae: 0.0662 - val_loss: 0.0088 - val_mae: 0.0724\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0076 - mae: 0.0655 - val_loss: 0.0114 - val_mae: 0.0846\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0088 - mae: 0.0714 - val_loss: 0.0082 - val_mae: 0.0710\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0078 - mae: 0.0671 - val_loss: 0.0082 - val_mae: 0.0696\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0084 - val_mae: 0.0715\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0077 - mae: 0.0664 - val_loss: 0.0097 - val_mae: 0.0761\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0076 - mae: 0.0657 - val_loss: 0.0069 - val_mae: 0.0628\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0079 - mae: 0.0675 - val_loss: 0.0074 - val_mae: 0.0658\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 381us/step - loss: 0.0079 - mae: 0.0669 - val_loss: 0.0076 - val_mae: 0.0662\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0082 - mae: 0.0684 - val_loss: 0.0096 - val_mae: 0.0773\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0081 - mae: 0.0679 - val_loss: 0.0078 - val_mae: 0.0680\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0083 - mae: 0.0683 - val_loss: 0.0082 - val_mae: 0.0698\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0082 - mae: 0.0689 - val_loss: 0.0072 - val_mae: 0.0644\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0077 - mae: 0.0661 - val_loss: 0.0074 - val_mae: 0.0647\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0081 - mae: 0.0678 - val_loss: 0.0088 - val_mae: 0.0722\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0085 - mae: 0.0701 - val_loss: 0.0076 - val_mae: 0.0685\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0080 - mae: 0.0677 - val_loss: 0.0070 - val_mae: 0.0639\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0076 - mae: 0.0656 - val_loss: 0.0080 - val_mae: 0.0677\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0081 - mae: 0.0679 - val_loss: 0.0072 - val_mae: 0.0656\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0077 - mae: 0.0665 - val_loss: 0.0091 - val_mae: 0.0747\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0077 - mae: 0.0660 - val_loss: 0.0079 - val_mae: 0.0667\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0076 - mae: 0.0660 - val_loss: 0.0070 - val_mae: 0.0638\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0082 - mae: 0.0686 - val_loss: 0.0080 - val_mae: 0.0690\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0079 - mae: 0.0676 - val_loss: 0.0087 - val_mae: 0.0721\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0083 - mae: 0.0692 - val_loss: 0.0071 - val_mae: 0.0654\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0078 - mae: 0.0671 - val_loss: 0.0077 - val_mae: 0.0680\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 663us/step - loss: 0.0246 - mae: 0.1019 - val_loss: 0.0078 - val_mae: 0.0676\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 384us/step - loss: 0.0060 - mae: 0.0572 - val_loss: 0.0070 - val_mae: 0.0636\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0054 - mae: 0.0544 - val_loss: 0.0065 - val_mae: 0.0611\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0052 - mae: 0.0535 - val_loss: 0.0068 - val_mae: 0.0630\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0050 - mae: 0.0522 - val_loss: 0.0060 - val_mae: 0.0584\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0062 - val_mae: 0.0599\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0049 - mae: 0.0516 - val_loss: 0.0056 - val_mae: 0.0557\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0049 - mae: 0.0516 - val_loss: 0.0063 - val_mae: 0.0591\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0061 - val_mae: 0.0590\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0058 - val_mae: 0.0569\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 509us/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0056 - val_mae: 0.0558\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0059 - val_mae: 0.0578\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0046 - mae: 0.0502 - val_loss: 0.0065 - val_mae: 0.0603\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0047 - mae: 0.0509 - val_loss: 0.0058 - val_mae: 0.0573\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0066 - val_mae: 0.0608\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0046 - mae: 0.0507 - val_loss: 0.0060 - val_mae: 0.0588\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0046 - mae: 0.0506 - val_loss: 0.0061 - val_mae: 0.0578\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0046 - mae: 0.0503 - val_loss: 0.0060 - val_mae: 0.0574\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0046 - mae: 0.0506 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0046 - mae: 0.0506 - val_loss: 0.0068 - val_mae: 0.0613\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0045 - mae: 0.0502 - val_loss: 0.0065 - val_mae: 0.0604\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0045 - mae: 0.0500 - val_loss: 0.0059 - val_mae: 0.0575\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 412us/step - loss: 0.0045 - mae: 0.0498 - val_loss: 0.0067 - val_mae: 0.0624\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0045 - mae: 0.0499 - val_loss: 0.0058 - val_mae: 0.0568\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0060 - val_mae: 0.0569\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0059 - val_mae: 0.0577\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0045 - mae: 0.0498 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0044 - mae: 0.0495 - val_loss: 0.0059 - val_mae: 0.0584\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0045 - mae: 0.0498 - val_loss: 0.0061 - val_mae: 0.0587\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0045 - mae: 0.0502 - val_loss: 0.0068 - val_mae: 0.0629\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0060 - val_mae: 0.0578\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0045 - mae: 0.0496 - val_loss: 0.0060 - val_mae: 0.0577\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0044 - mae: 0.0496 - val_loss: 0.0058 - val_mae: 0.0571\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0057 - val_mae: 0.0555\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0063 - val_mae: 0.0586\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0044 - mae: 0.0496 - val_loss: 0.0059 - val_mae: 0.0582\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0045 - mae: 0.0500 - val_loss: 0.0058 - val_mae: 0.0563\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0044 - mae: 0.0494 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.0060 - val_mae: 0.0577\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0044 - mae: 0.0491 - val_loss: 0.0061 - val_mae: 0.0578\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0044 - mae: 0.0491 - val_loss: 0.0060 - val_mae: 0.0569\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0044 - mae: 0.0492 - val_loss: 0.0061 - val_mae: 0.0579\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 426us/step - loss: 0.0045 - mae: 0.0499 - val_loss: 0.0058 - val_mae: 0.0565\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 400us/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0061 - val_mae: 0.0584\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0044 - mae: 0.0491 - val_loss: 0.0062 - val_mae: 0.0589\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0062 - val_mae: 0.0585\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 385us/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.0059 - val_mae: 0.0574\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0487 - val_loss: 0.0064 - val_mae: 0.0599\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0062 - val_mae: 0.0601\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0062 - val_mae: 0.0592\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0043 - mae: 0.0487 - val_loss: 0.0059 - val_mae: 0.0572\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 381us/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0059 - val_mae: 0.0584\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0060 - val_mae: 0.0573\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0581\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.0060 - val_mae: 0.0581\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0044 - mae: 0.0492 - val_loss: 0.0059 - val_mae: 0.0578\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0484 - val_loss: 0.0062 - val_mae: 0.0585\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0062 - val_mae: 0.0593\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0061 - val_mae: 0.0584\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0059 - val_mae: 0.0572\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 384us/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0060 - val_mae: 0.0580\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0487 - val_loss: 0.0057 - val_mae: 0.0563\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 507us/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0573\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0059 - val_mae: 0.0571\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0058 - val_mae: 0.0569\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0061 - val_mae: 0.0581\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0059 - val_mae: 0.0572\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0065 - val_mae: 0.0603\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0483 - val_loss: 0.0059 - val_mae: 0.0571\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0043 - mae: 0.0486 - val_loss: 0.0060 - val_mae: 0.0580\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0062 - val_mae: 0.0585\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0477 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0043 - mae: 0.0490 - val_loss: 0.0062 - val_mae: 0.0589\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0487 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0041 - mae: 0.0476 - val_loss: 0.0057 - val_mae: 0.0575\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0063 - val_mae: 0.0610\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0477 - val_loss: 0.0060 - val_mae: 0.0567\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0042 - mae: 0.0483 - val_loss: 0.0059 - val_mae: 0.0568\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0060 - val_mae: 0.0573\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0058 - val_mae: 0.0562\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0059 - val_mae: 0.0571\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0058 - val_mae: 0.0568\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0060 - val_mae: 0.0574\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0059 - val_mae: 0.0568\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0042 - mae: 0.0485 - val_loss: 0.0060 - val_mae: 0.0565\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0482 - val_loss: 0.0060 - val_mae: 0.0576\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0477 - val_loss: 0.0061 - val_mae: 0.0580\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 382us/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0567\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0059 - val_mae: 0.0572\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0041 - mae: 0.0477 - val_loss: 0.0060 - val_mae: 0.0576\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0042 - mae: 0.0480 - val_loss: 0.0059 - val_mae: 0.0580\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0058 - val_mae: 0.0563\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0041 - mae: 0.0477 - val_loss: 0.0061 - val_mae: 0.0577\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0042 - mae: 0.0483 - val_loss: 0.0062 - val_mae: 0.0583\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0060 - val_mae: 0.0576\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 411us/step - loss: 0.0041 - mae: 0.0476 - val_loss: 0.0063 - val_mae: 0.0597\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0042 - mae: 0.0481 - val_loss: 0.0055 - val_mae: 0.0549\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0041 - mae: 0.0474 - val_loss: 0.0058 - val_mae: 0.0566\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 664us/step - loss: 0.1021 - mae: 0.2350 - val_loss: 0.0125 - val_mae: 0.0879\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 392us/step - loss: 0.0131 - mae: 0.0841 - val_loss: 0.0098 - val_mae: 0.0773\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0104 - mae: 0.0746 - val_loss: 0.0087 - val_mae: 0.0723\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0089 - mae: 0.0692 - val_loss: 0.0078 - val_mae: 0.0683\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 507us/step - loss: 0.0076 - mae: 0.0644 - val_loss: 0.0071 - val_mae: 0.0649\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0067 - mae: 0.0604 - val_loss: 0.0069 - val_mae: 0.0635\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.0065 - val_mae: 0.0614\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0058 - mae: 0.0559 - val_loss: 0.0066 - val_mae: 0.0620\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0056 - mae: 0.0549 - val_loss: 0.0064 - val_mae: 0.0612\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0054 - mae: 0.0542 - val_loss: 0.0063 - val_mae: 0.0605\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0053 - mae: 0.0535 - val_loss: 0.0065 - val_mae: 0.0611\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0052 - mae: 0.0530 - val_loss: 0.0061 - val_mae: 0.0590\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0052 - mae: 0.0527 - val_loss: 0.0061 - val_mae: 0.0592\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0051 - mae: 0.0526 - val_loss: 0.0063 - val_mae: 0.0595\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 382us/step - loss: 0.0051 - mae: 0.0522 - val_loss: 0.0065 - val_mae: 0.0606\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0050 - mae: 0.0521 - val_loss: 0.0062 - val_mae: 0.0592\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0050 - mae: 0.0516 - val_loss: 0.0061 - val_mae: 0.0590\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0050 - mae: 0.0515 - val_loss: 0.0062 - val_mae: 0.0590\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.0060 - val_mae: 0.0581\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0049 - mae: 0.0514 - val_loss: 0.0061 - val_mae: 0.0590\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0049 - mae: 0.0514 - val_loss: 0.0063 - val_mae: 0.0598\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0049 - mae: 0.0510 - val_loss: 0.0061 - val_mae: 0.0592\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.0063 - val_mae: 0.0592\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0049 - mae: 0.0510 - val_loss: 0.0064 - val_mae: 0.0607\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0048 - mae: 0.0509 - val_loss: 0.0063 - val_mae: 0.0595\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0048 - mae: 0.0506 - val_loss: 0.0061 - val_mae: 0.0588\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0048 - mae: 0.0505 - val_loss: 0.0059 - val_mae: 0.0577\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0048 - mae: 0.0504 - val_loss: 0.0062 - val_mae: 0.0594\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0048 - mae: 0.0506 - val_loss: 0.0064 - val_mae: 0.0610\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0047 - mae: 0.0503 - val_loss: 0.0061 - val_mae: 0.0582\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0048 - mae: 0.0504 - val_loss: 0.0061 - val_mae: 0.0580\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0047 - mae: 0.0502 - val_loss: 0.0060 - val_mae: 0.0578\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0047 - mae: 0.0502 - val_loss: 0.0060 - val_mae: 0.0577\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 399us/step - loss: 0.0047 - mae: 0.0499 - val_loss: 0.0059 - val_mae: 0.0579\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 419us/step - loss: 0.0047 - mae: 0.0498 - val_loss: 0.0059 - val_mae: 0.0583\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0047 - mae: 0.0500 - val_loss: 0.0059 - val_mae: 0.0577\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0046 - mae: 0.0497 - val_loss: 0.0060 - val_mae: 0.0581\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0046 - mae: 0.0496 - val_loss: 0.0063 - val_mae: 0.0593\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0046 - mae: 0.0496 - val_loss: 0.0060 - val_mae: 0.0583\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 525us/step - loss: 0.0046 - mae: 0.0497 - val_loss: 0.0061 - val_mae: 0.0587\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0046 - mae: 0.0494 - val_loss: 0.0058 - val_mae: 0.0573\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0046 - mae: 0.0494 - val_loss: 0.0062 - val_mae: 0.0593\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0046 - mae: 0.0493 - val_loss: 0.0058 - val_mae: 0.0566\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0046 - mae: 0.0493 - val_loss: 0.0058 - val_mae: 0.0568\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0046 - mae: 0.0492 - val_loss: 0.0065 - val_mae: 0.0602\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0045 - mae: 0.0491 - val_loss: 0.0061 - val_mae: 0.0582\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0045 - mae: 0.0489 - val_loss: 0.0059 - val_mae: 0.0575\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0045 - mae: 0.0492 - val_loss: 0.0059 - val_mae: 0.0574\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 409us/step - loss: 0.0045 - mae: 0.0490 - val_loss: 0.0060 - val_mae: 0.0583\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0045 - mae: 0.0489 - val_loss: 0.0058 - val_mae: 0.0574\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0045 - mae: 0.0489 - val_loss: 0.0059 - val_mae: 0.0569\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0045 - mae: 0.0490 - val_loss: 0.0058 - val_mae: 0.0568\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0059 - val_mae: 0.0574\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0045 - mae: 0.0488 - val_loss: 0.0060 - val_mae: 0.0582\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0060 - val_mae: 0.0580\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0059 - val_mae: 0.0575\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0045 - mae: 0.0488 - val_loss: 0.0061 - val_mae: 0.0581\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0058 - val_mae: 0.0563\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0573\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0044 - mae: 0.0485 - val_loss: 0.0062 - val_mae: 0.0585\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0044 - mae: 0.0485 - val_loss: 0.0058 - val_mae: 0.0565\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0044 - mae: 0.0483 - val_loss: 0.0056 - val_mae: 0.0553\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.0060 - val_mae: 0.0575\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0044 - mae: 0.0485 - val_loss: 0.0063 - val_mae: 0.0584\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0044 - mae: 0.0481 - val_loss: 0.0059 - val_mae: 0.0573\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0044 - mae: 0.0482 - val_loss: 0.0059 - val_mae: 0.0577\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0044 - mae: 0.0483 - val_loss: 0.0058 - val_mae: 0.0572\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0060 - val_mae: 0.0575\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 406us/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.0060 - val_mae: 0.0577\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 527us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0061 - val_mae: 0.0579\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0058 - val_mae: 0.0561\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0043 - mae: 0.0479 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0043 - mae: 0.0482 - val_loss: 0.0058 - val_mae: 0.0571\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0477 - val_loss: 0.0058 - val_mae: 0.0561\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 383us/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0059 - val_mae: 0.0565\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0043 - mae: 0.0476 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0477 - val_loss: 0.0056 - val_mae: 0.0556\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0043 - mae: 0.0477 - val_loss: 0.0057 - val_mae: 0.0556\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0043 - mae: 0.0476 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0043 - mae: 0.0476 - val_loss: 0.0059 - val_mae: 0.0564\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0043 - mae: 0.0476 - val_loss: 0.0059 - val_mae: 0.0563\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0042 - mae: 0.0475 - val_loss: 0.0058 - val_mae: 0.0565\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0058 - val_mae: 0.0566\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0042 - mae: 0.0475 - val_loss: 0.0057 - val_mae: 0.0558\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0042 - mae: 0.0475 - val_loss: 0.0059 - val_mae: 0.0569\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0055 - val_mae: 0.0551\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.0057 - val_mae: 0.0559\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0473 - val_loss: 0.0057 - val_mae: 0.0556\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 406us/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0059 - val_mae: 0.0571\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.0058 - val_mae: 0.0561\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0042 - mae: 0.0473 - val_loss: 0.0056 - val_mae: 0.0548\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0042 - mae: 0.0474 - val_loss: 0.0056 - val_mae: 0.0552\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0057 - val_mae: 0.0557\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 669us/step - loss: 0.3345 - mae: 0.5349 - val_loss: 0.2638 - val_mae: 0.4736\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.2455 - mae: 0.4444 - val_loss: 0.1799 - val_mae: 0.3753\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.1527 - mae: 0.3321 - val_loss: 0.0989 - val_mae: 0.2609\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0814 - mae: 0.2288 - val_loss: 0.0480 - val_mae: 0.1724\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0438 - mae: 0.1629 - val_loss: 0.0262 - val_mae: 0.1262\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0283 - mae: 0.1297 - val_loss: 0.0182 - val_mae: 0.1054\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0219 - mae: 0.1130 - val_loss: 0.0149 - val_mae: 0.0954\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0188 - mae: 0.1035 - val_loss: 0.0133 - val_mae: 0.0901\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0169 - mae: 0.0973 - val_loss: 0.0124 - val_mae: 0.0870\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0156 - mae: 0.0930 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0147 - mae: 0.0897 - val_loss: 0.0113 - val_mae: 0.0832\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0140 - mae: 0.0871 - val_loss: 0.0110 - val_mae: 0.0818\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0134 - mae: 0.0848 - val_loss: 0.0107 - val_mae: 0.0805\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0129 - mae: 0.0830 - val_loss: 0.0104 - val_mae: 0.0795\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0125 - mae: 0.0815 - val_loss: 0.0102 - val_mae: 0.0786\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0121 - mae: 0.0802 - val_loss: 0.0100 - val_mae: 0.0777\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0118 - mae: 0.0791 - val_loss: 0.0098 - val_mae: 0.0769\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0115 - mae: 0.0778 - val_loss: 0.0097 - val_mae: 0.0761\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0112 - mae: 0.0769 - val_loss: 0.0095 - val_mae: 0.0755\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0110 - mae: 0.0759 - val_loss: 0.0093 - val_mae: 0.0747\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0107 - mae: 0.0750 - val_loss: 0.0092 - val_mae: 0.0740\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0105 - mae: 0.0741 - val_loss: 0.0091 - val_mae: 0.0733\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0102 - mae: 0.0732 - val_loss: 0.0089 - val_mae: 0.0724\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 366us/step - loss: 0.0100 - mae: 0.0724 - val_loss: 0.0088 - val_mae: 0.0719\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0098 - mae: 0.0715 - val_loss: 0.0086 - val_mae: 0.0712\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0095 - mae: 0.0707 - val_loss: 0.0084 - val_mae: 0.0704\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 418us/step - loss: 0.0093 - mae: 0.0699 - val_loss: 0.0083 - val_mae: 0.0698\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 543us/step - loss: 0.0091 - mae: 0.0690 - val_loss: 0.0082 - val_mae: 0.0694\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0089 - mae: 0.0684 - val_loss: 0.0081 - val_mae: 0.0689\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0087 - mae: 0.0675 - val_loss: 0.0079 - val_mae: 0.0680\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 381us/step - loss: 0.0085 - mae: 0.0669 - val_loss: 0.0078 - val_mae: 0.0674\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0083 - mae: 0.0662 - val_loss: 0.0077 - val_mae: 0.0669\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 415us/step - loss: 0.0081 - mae: 0.0655 - val_loss: 0.0077 - val_mae: 0.0667\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 380us/step - loss: 0.0080 - mae: 0.0649 - val_loss: 0.0075 - val_mae: 0.0660\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 382us/step - loss: 0.0078 - mae: 0.0642 - val_loss: 0.0074 - val_mae: 0.0655\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 371us/step - loss: 0.0077 - mae: 0.0637 - val_loss: 0.0074 - val_mae: 0.0653\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 379us/step - loss: 0.0075 - mae: 0.0631 - val_loss: 0.0073 - val_mae: 0.0648\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0074 - mae: 0.0626 - val_loss: 0.0072 - val_mae: 0.0644\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0072 - mae: 0.0620 - val_loss: 0.0071 - val_mae: 0.0640\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0071 - mae: 0.0616 - val_loss: 0.0070 - val_mae: 0.0637\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 372us/step - loss: 0.0070 - mae: 0.0611 - val_loss: 0.0070 - val_mae: 0.0634\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0069 - mae: 0.0606 - val_loss: 0.0069 - val_mae: 0.0630\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0068 - mae: 0.0602 - val_loss: 0.0068 - val_mae: 0.0627\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 370us/step - loss: 0.0067 - mae: 0.0598 - val_loss: 0.0068 - val_mae: 0.0625\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 368us/step - loss: 0.0066 - mae: 0.0594 - val_loss: 0.0068 - val_mae: 0.0625\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0065 - mae: 0.0591 - val_loss: 0.0067 - val_mae: 0.0621\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 369us/step - loss: 0.0065 - mae: 0.0587 - val_loss: 0.0066 - val_mae: 0.0619\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0064 - mae: 0.0585 - val_loss: 0.0066 - val_mae: 0.0618\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 375us/step - loss: 0.0063 - mae: 0.0581 - val_loss: 0.0066 - val_mae: 0.0617\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0063 - mae: 0.0579 - val_loss: 0.0066 - val_mae: 0.0614\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 376us/step - loss: 0.0062 - mae: 0.0576 - val_loss: 0.0065 - val_mae: 0.0614\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 386us/step - loss: 0.0062 - mae: 0.0573 - val_loss: 0.0066 - val_mae: 0.0615\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 385us/step - loss: 0.0061 - mae: 0.0571 - val_loss: 0.0066 - val_mae: 0.0614\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 526us/step - loss: 0.0061 - mae: 0.0568 - val_loss: 0.0064 - val_mae: 0.0609\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 367us/step - loss: 0.0060 - mae: 0.0566 - val_loss: 0.0064 - val_mae: 0.0609\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 374us/step - loss: 0.0060 - mae: 0.0564 - val_loss: 0.0064 - val_mae: 0.0609\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 373us/step - loss: 0.0059 - mae: 0.0563 - val_loss: 0.0065 - val_mae: 0.0612\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 390us/step - loss: 0.0059 - mae: 0.0560 - val_loss: 0.0064 - val_mae: 0.0609\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 378us/step - loss: 0.0059 - mae: 0.0559 - val_loss: 0.0064 - val_mae: 0.0607\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 383us/step - loss: 0.0058 - mae: 0.0557 - val_loss: 0.0064 - val_mae: 0.0608\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 377us/step - loss: 0.0058 - mae: 0.0556 - val_loss: 0.0064 - val_mae: 0.0610\n",
      "Epoch 62/100\n",
      "  1/144 [..............................] - ETA: 0s - loss: 0.0050 - mae: 0.0517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(num_layers, units, learning_rate)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Train the model (use early stopping or set epochs according to your needs)\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set verbose=1 to see training output\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data\u001b[39;00m\n\u001b[1;32m     86\u001b[0m val_loss, val_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2454\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m-> 2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2064\u001b[0m, in \u001b[0;36mConcreteFunction.captured_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcaptured_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns external Tensors captured by this function.\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \n\u001b[1;32m   2062\u001b[0m \u001b[38;5;124;03m  self.__call__(*args) passes `args + self.captured_inputs` to the function.\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2064\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_captured_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.10/site-packages/tensorflow/python/util/nest.py:453\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    452\u001b[0m expand_composites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "\n",
    "    # Open velocity data set\n",
    "    ds = xr.open_dataset('/Users/smata/Downloads/processedData/velocityData.nc')\n",
    "\n",
    "    # Reformat to Pandas dataframe\n",
    "    df_u = ds['u'].to_dataframe().reset_index()\n",
    "    df_v = ds['v'].to_dataframe().reset_index()\n",
    "\n",
    "    df_u = df_u.pivot(index='time', columns='height', values='u')\n",
    "    df_v = df_v.pivot(index='time', columns='height', values='v')\n",
    "\n",
    "    df_u.columns = [f'u_{int(height)}m' for height in df_u.columns]\n",
    "    df_v.columns = [f'v_{int(height)}m' for height in df_v.columns]\n",
    "\n",
    "    df = pd.concat([df_u, df_v], axis=1)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.insert(0, 'L', ds.L.values)\n",
    "    df.insert(0, 'TKE', ds.TKE.values)\n",
    "\n",
    "    df.insert(0, 'hour_sin', np.sin(2 * np.pi * ds.hr_day.values / 24))\n",
    "    df.insert(0, 'hour_cos', np.cos(2 * np.pi * ds.hr_day.values / 24))\n",
    "\n",
    "    df.insert(0, 'day_sin', np.sin(2 * np.pi * ds.day_yr.values / 365))\n",
    "    df.insert(0, 'day_cos', np.cos(2 * np.pi * ds.day_yr.values / 365))\n",
    "\n",
    "    # Standardize data\n",
    "    windCols = [col for col in df.columns if col.startswith('u_') or col.startswith('v_')]\n",
    "    stabilityCols = ['TKE', 'L']\n",
    "\n",
    "    wind_scaler = MinMaxScaler()\n",
    "    df[windCols] = wind_scaler.fit_transform(df[windCols])\n",
    "\n",
    "    stability_scaler = MinMaxScaler()\n",
    "    df[stabilityCols] = stability_scaler.fit_transform(df[stabilityCols])\n",
    "\n",
    "    # Define and extract input and output columns\n",
    "    inputs = ['day_cos', 'day_sin', 'hour_cos', 'hour_sin', 'TKE', 'L', 'u_10m', 'v_10m']\n",
    "\n",
    "    X = df[inputs].values\n",
    "    y = df[windCols].values\n",
    "\n",
    "    # Create input and output arrays\n",
    "    split_index = int(0.8 * len(X))\n",
    "\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    num_layers_options    = np.arange(1, 10)\n",
    "    units_options         = [32, 64, 128, 256, 512]\n",
    "    learning_rate_options = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "    def build_model(num_layers, units, learning_rate):\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            model.add(keras.layers.Dense(units = units, activation = 'relu'))\n",
    "        \n",
    "        model.add(keras.layers.Dense(y_train.shape[1]))  # Output size should match the number of wind components\n",
    "        \n",
    "        model.compile(optimizer = keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                    loss = 'mean_squared_error',\n",
    "                    metrics = ['mae'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    param_grid = list(product(num_layers_options, units_options, learning_rate_options))\n",
    "\n",
    "    best_model  = None\n",
    "    best_mae    = float('inf')\n",
    "    best_params = None\n",
    "\n",
    "    for num_layers, units, learning_rate in param_grid:\n",
    "        # Create and train the model\n",
    "        model = build_model(num_layers, units, learning_rate)\n",
    "        \n",
    "        # Train the model (use early stopping or set epochs according to your needs)\n",
    "        history = model.fit(X_train, y_train, \n",
    "                            validation_split = 0.2, \n",
    "                            epochs = 100, \n",
    "                            batch_size = 32,\n",
    "                            verbose = 1)  # Set verbose=1 to see training output\n",
    "\n",
    "        # Evaluate the model on validation data\n",
    "        val_loss, val_mae = model.evaluate(X_test, y_test, verbose = 0)\n",
    "        \n",
    "        # Check if this model is the best\n",
    "        if val_mae < best_mae:\n",
    "            best_mae    = val_mae\n",
    "            best_model  = model\n",
    "            best_params = (num_layers, units, learning_rate)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best MAE:\", best_mae)\n",
    "    print(\"Best parameters: Layers:\", best_params[0], \"Units:\", best_params[1], \"Learning Rate:\", best_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
